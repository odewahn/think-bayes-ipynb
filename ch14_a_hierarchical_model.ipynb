{
  "metadata": {
    "name": "A Hierarchical Model"
  },
  "nbformat": 3,
  "nbformat_minor": 0,
  "worksheets": [
    {
      "cells": [
        {
          "cell_type": "heading",
          "level": 1,
          "metadata": {
          },
          "source": "A Hierarchical Model"
        },
        {
          "cell_type": "heading",
          "level": 2,
          "metadata": {
          },
          "source": "The Geiger counter problem"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "I got the idea for the following problem from Tom Campbell-Ricketts, author of the Maximum Entropy blog at [http://maximum-entropy-blog.blogspot.com](http://maximum-entropy-blog.blogspot.com). And he got the idea from E.T. Jaynes, author of the classic _Probability Theory: The Logic of Science_:"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "<blockquote><p>Suppose that a radioactive source emits particles toward a Geiger\n      counter at an average rate of <em>r</em>\n      particles per second, but the counter only registers a fraction,\n      <em>f</em>, of the particles that hit it. If\n      <em>f</em> is 10% and the counter registers 15\n      particles in a one second interval, what is the posterior distribution\n      of <em>n</em>, the actual number of particles\n      that hit the counter, and <em>r</em>, the\n      average rate particles are emitted?</p></blockquote>\n"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "To get started on a problem like this, think about the chain of causation that starts with the parameters of the system and ends with the observed data:"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "<ol>\n<li><p>The source emits particles at an average rate, <em>r</em>.</p></li>\n<li><p>During any given second, the source emits <em>n</em> particles toward the counter.</p></li>\n<li><p>Out of those <em>n</em> particles, some\n        number, <em>k</em>, get counted.</p></li>\n</ol>\n"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "The probability that an atom decays is the same at any point in time, so radioactive decay is well modeled by a Poisson process. Given _r_, the distribution of _n_ is Poisson distribution with parameter _r_."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "And if we assume that the probability of detection for each particle is independent of the others, the distribution of _k_ is the binomial distribution with parameters _n_ and _f_."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "Given the parameters of the system, we can find the distribution of the data. So we can solve what is called the **forward problem**."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "Now we want to go the other way: given the data, we want the distribution of the parameters. This is called the **inverse problem**. And if you can solve the forward problem, you can use Bayesian methods to solve the inverse problem."
        },
        {
          "cell_type": "heading",
          "level": 2,
          "metadata": {
          },
          "source": "Start simple"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "Letâs start with a simple version of the problem where we know the value of _r_. We are given the value of _f_, so all we have to do is estimate _n_."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "I define a Suite called `Detector` that models the behavior of the detector and estimates _n_."
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "class Detector(thinkbayes.Suite):\n\n    def __init__(self, r, f, high=500, step=1):\n        pmf = thinkbayes.MakePoissonPmf(r, high, step=step)\n        thinkbayes.Suite.__init__(self, pmf, name=r)\n        self.r = r\n        self.f = f",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "If the average emission rate is _r_ particles per second, the distribution of _n_ is Poisson with parameter _r_. `high` and `step` determine the upper bound for _n_ and the step size between hypothetical values."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "Now we need a likelihood function:"
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "# class Detector\n\n    def Likelihood(self, data, hypo):\n        k = data\n        n = hypo\n        p = self.f\n\n        return thinkbayes.EvalBinomialPmf(k, n, p)",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "`data` is the number of particles detected, and `hypo` is the hypothetical number of particles emitted, _n_."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "If there are actually _n_ particles, and the probability of detecting any one of them is _f_, the probability of detecting _k_ particles is given by the binomial distribution."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "Thatâs it for the Detector. We can try it out for a range of values of _r_:"
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "    f = 0.1\n    k = 15\n\n    for r in [100, 250, 400]:\n        suite = Detector(r, f, step=1)\n        suite.Update(k)\n        print suite.MaximumLikelihood()",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "FigureÂ 14-1 shows the posterior distribution of _n_ for several given values of _r_."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "<figure id=\"fig.jaynes1\" style=\"float: True\"><img src=\"files/images/thba_1401.png\"><figcaption>Posterior distribution of n for three values of r.</figcaption></figure>"
        },
        {
          "cell_type": "heading",
          "level": 2,
          "metadata": {
          },
          "source": "Make it hierarchical"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "In the previous section, we assume _r_ is known. Now letâs relax that assumption. I define another Suite, called `Emitter` , that models the behavior of the emitter and estimates _r_:"
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "class Emitter(thinkbayes.Suite):\n\n    def __init__(self, rs, f=0.1):\n        detectors = [Detector(r, f) for r in rs]\n        thinkbayes.Suite.__init__(self, detectors)",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "`rs` is a sequence of hypothetical value for _r_. `detectors` is a sequence of Detector objects, one for each value of _r_. The values in the Suite are Detectors, so Emitter is a **meta-Suite**; that is, a Suite that contains other Suites as values."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "To update the Emitter, we have to compute the likelihood of the data under each hypothetical value of _r_. But each value of _r_ is represented by a Detector that contains a range of values for _n_."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "To compute the likelihood of the data for a given Detector, we loop through the values of _n_ and add up the total probability of _k_. Thatâs what `SuiteLikelihood` does:"
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "# class Detector\n\n    def SuiteLikelihood(self, data):\n        total = 0\n        for hypo, prob in self.Items():\n            like = self.Likelihood(data, hypo)\n            total += prob * like\n        return total",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "Now we can write the Likelihood function for the Emitter:"
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "# class Detector\n\n    def Likelihood(self, data, hypo):\n        detector = hypo\n        like = detector.SuiteLikelihood(data)\n        return like",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "Each `hypo` is a Detector, so we can invoke `SuiteLikelihood` to get the likelihood of the data under the hypothesis."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "After we update the Emitter, we have to update each of the Detectors, too."
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "# class Detector\n\n    def Update(self, data):\n        thinkbayes.Suite.Update(self, data)\n        \n        for detector in self.Values():\n            detector.Update()",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "A model like this, with multiple levels of Suites, is called **hierarchical**."
        },
        {
          "cell_type": "heading",
          "level": 2,
          "metadata": {
          },
          "source": "A little optimization"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "You might recognize `SuiteLikelihood` ; we saw it in [âMaking a fair comparisonâ](ch11.html#suitelike). At the time, I pointed out that we didnât really need it, because the total probability computed by `SuiteLikelihood` is exactly the normalizing constant computed and returned by `Update` ."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "So instead of updating the Emitter and then updating the Detectors, we can do both steps at the same time, using the result from `Detector.Update` as the likelihood of Emitter."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "Hereâs the streamlined version of `Emitter.Likelihood` :"
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "# class Emitter\n\n    def Likelihood(self, data, hypo):\n        return hypo.Update(data)",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "And with this version of `Likelihood` we can use the default version of `Update` . So this version has fewer lines of code, and it runs faster because it does not compute the normalizing constant twice."
        },
        {
          "cell_type": "heading",
          "level": 2,
          "metadata": {
          },
          "source": "Extracting the posteriors"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "After we update the Emitter, we can get the posterior distribution of _r_ by looping through the Detectors and their probabilities:"
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "# class Emitter\n\n    def DistOfR(self):\n        items = [(detector.r, prob) for detector, prob in self.Items()]\n        return thinkbayes.MakePmfFromItems(items)",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "`items` is a list of values of _r_ and their probabilities. The result is the Pmf of _r_."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "To get the posterior distribution of _n_, we have to compute the mixture of the Detectors. We can use `thinkbayes.MakeMixture` , which takes a meta-Pmf that maps from each distribution to its probability. And thatâs exactly what the Emitter is:"
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "# class Emitter\n\n    def DistOfN(self):\n        return thinkbayes.MakeMixture(self)",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "FigureÂ 14-2 shows the results. Not surprisingly, the most likely value for _n_ is 150. Given _f_ and _n_, the expected count is k=fn, so given _f_ and _k_, the expected value of _n_ is k/f, which is 150."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "<figure id=\"fig.jaynes2\" style=\"float: True\"><img src=\"files/images/thba_1402.png\"><figcaption>Posterior distributions of n and r.</figcaption></figure>"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "And if 150 particles are emitted in one second, the most likely value of _r_ is 150 particles per second. So the posterior distribution of _r_ is also centered on 150."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "The posterior distributions of _r_ and _n_ are similar; the only difference is that we are slightly less certain about _n_. In general, we can be more certain about the long-range emission rate, _r_, than about the number of particles emitted in any particular second, _n_."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "You can download the code in this chapter from [http://thinkbayes.com/jaynes.py](http://thinkbayes.com/jaynes.py). For more information see [âWorking with the codeâ](preface01.html#download)."
        },
        {
          "cell_type": "heading",
          "level": 2,
          "metadata": {
          },
          "source": "Discussion"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "The Geiger counter problem demonstrates the connection between causation and hierarchical modeling. In the example, the emission rate _r_ has a causal effect on the number of particles, _n_, which has a causal effect on the particle count, _k_."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "The hierarchical model reflects the structure of the system, with causes at the top and effects at the bottom."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "<ol>\n<li><p>At the top level, we start with a range of hypothetical values\n        for <em>r</em>.</p></li>\n<li><p>For each value of <em>r</em>, we have a\n        range of values for <em>n</em>, and the prior\n        distribution of <em>n</em> depends on\n        <em>r</em>.</p></li>\n<li><p>When we update the model, we go bottom-up. We compute a\n        posterior distribution of <em>n</em> for each\n        value of <em>r</em>, then compute the\n        posterior distribution of <em>r</em>.</p></li>\n</ol>\n"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "So causal information flows down the hierarchy, and inference flows up."
        },
        {
          "cell_type": "heading",
          "level": 2,
          "metadata": {
          },
          "source": "Exercises"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "<div id=\"a0000006328\" class=\"exercise\" data-type=\"example\">\n<h5></h5>\n<p>This exercise is also inspired by an example in Jaynes,\n        <em>Probability Theory</em>.</p>\n<p>Suppose you buy a mosquito trap that is supposed to reduce the\n        population of mosquitoes near your house. Each week, you empty the\n        trap and count the number of mosquitoes captured. After the first\n        week, you count 30 mosquitoes. After the second week, you count 20\n        mosquitoes. Estimate the percentage change in the number of mosquitoes\n        in your yard.</p>\n<p>To answer this question, you have to make some modeling\n        decisions. Here are some suggestions:</p>\n<ul>\n<li><p>Suppose that each week a large number of mosquitoes,\n            <em>N</em>, is bred in a wetland near your\n            home.</p></li>\n<li><p>During the week, some fraction of them, <em>f<sub>1</sub></em>, wander into your\n            yard, and of those some fraction, <em>f<sub>2</sub></em>, are caught in\n            the trap.</p></li>\n<li><p>Your solution should take into account your prior belief\n            about how much <em>N</em> is likely to\n            change from one week to the next. You can do that by adding a\n            level to the hierarchy to model the percent change in <em>N</em>.</p></li>\n</ul>\n</div>"
        }
      ],
      "metadata": {
      }
    }
  ]
}