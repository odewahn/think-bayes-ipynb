{
  "metadata": {
    "name": "Estimation"
  },
  "nbformat": 3,
  "nbformat_minor": 0,
  "worksheets": [
    {
      "cells": [
        {
          "cell_type": "heading",
          "level": 1,
          "metadata": {
          },
          "source": "Estimation"
        },
        {
          "cell_type": "heading",
          "level": 2,
          "metadata": {
          },
          "source": "The dice problem"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "Suppose I have a box of dice that contains a 4-sided die, a 6-sided die, an 8-sided die, a 12-sided die, and a 20-sided die. If you have ever played _Dungeons&Dragons_, you know what I am talking about."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "Suppose I select a die from the box at random, roll it, and get a 6. What is the probability that I rolled each die?"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "Let me suggest a three-step strategy for approaching a problem like this."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "<ol>\n<li><p>Choose a representation for the hypotheses.</p></li>\n<li><p>Choose a representation for the data.</p></li>\n<li><p>Write the likelihood function.</p></li>\n</ol>\n"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "In previous examples I used strings to represent hypotheses and data, but for the die problem Iâll use numbers. Specifically, Iâll use the integers 4, 6, 8, 12, and 20 to represent hypotheses:"
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "    suite = Dice([4, 6, 8, 12, 20])",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "And integers from 1 to 20 for the data. These representations make it easy to write the likelihood function:"
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "class Dice(Suite):\n    def Likelihood(self, data, hypo):\n        if hypo < data:\n            return 0\n        else:\n            return 1.0/hypo",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "Hereâs how `Likelihood` works. If `hypo<data` , that means the roll is greater than the number of sides on the die. That canât happen, so the likelihood is 0."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "Otherwise the question is, âGiven that there are `hypo` sides, what is the chance of rolling `data` ?â The answer is `1/hypo` , regardless of `data` ."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "Here is the statement that does the update (if I roll a 6):"
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "    suite.Update(6)",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "And here is the posterior distribution:"
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "4 0.0\n6 0.392156862745\n8 0.294117647059\n12 0.196078431373\n20 0.117647058824",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "After we roll a 6, the probability for the 4-sided die is 0. The most likely alternative is the 6-sided die, but there is still almost a 12% chance for the 20-sided die."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "What if we roll a few more times and get 6, 8, 7, 7, 5, and 4?"
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "    for roll in [6, 8, 7, 7, 5, 4]:\n        suite.Update(roll)",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "With this data the 6-sided die is eliminated, and the 8-sided die seems quite likely. Here are the results:"
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "4 0.0\n6 0.0\n8 0.943248453672\n12 0.0552061280613\n20 0.0015454182665",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "Now the probability is 94% that we are rolling the 8-sided die, and less than 1% for the 20-sided die."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "The dice problem is based on an example I saw in Sanjoy Mahajanâs class on Bayesian inference. You can download the code in this section from [http://thinkbayes.com/dice.py](http://thinkbayes.com/dice.py). For more information see [âWorking with the codeâ](preface01.html#download)."
        },
        {
          "cell_type": "heading",
          "level": 2,
          "metadata": {
          },
          "source": "The locomotive problem"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "I found the locomotive problem in Frederick Mostellerâs, _Fifty Challenging Problems in Probability with Solutions_ (Dover, 1987):"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "<blockquote><p>âA railroad numbers its locomotives in order 1..N. One day you see\n      a locomotive with the number 60. Estimate how many locomotives the\n      railroad has.â</p></blockquote>\n"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "Based on this observation, we know the railroad has 60 or more locomotives. But how many more? To apply Bayesian reasoning, we can break this problem into two steps:"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "<ol>\n<li><p>What did we know about <em>N</em> before\n        we saw the data?</p></li>\n<li><p>For any given value of <em>N</em>, what\n        is the likelihood of seeing the data (a locomotive with number\n        60)?</p></li>\n</ol>\n"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "The answer to the first question is the prior. The answer to the second is the likelihood."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "We donât have much basis to choose a prior, but we can start with something simple and then consider alternatives. Letâs assume that _N_ is equally likely to be any value from 1 to 1000."
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "    hypos = xrange(1, 1001)",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "Now all we need is a likelihood function. In a hypothetical fleet of _N_ locomotives, what is the probability that we would see number 60? If we assume that there is only one train-operating company (or only one we care about) and that we are equally likely to see any of its locomotives, then the chance of seeing any particular locomotive is 1/N."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "Hereâs the likelihood function:"
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "class Train(Suite):\n    def Likelihood(self, data, hypo):\n        if hypo < data:\n            return 0\n        else:\n            return 1.0/hypo",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "This might look familiar; the likelihood functions for the locomotive problem and the dice problem are identical."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "Hereâs the update:"
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "    suite = Train(hypos)\n    suite.Update(60)",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "There are too many hypotheses to print, so I plotted the results in FigureÂ 3-1. Not surprisingly, all values of _N_ below 60 have been eliminated."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "<figure id=\"fig.train1\" style=\"float: True\"><img src=\"files/images/thba_0301.png\"><figcaption>Posterior distribution for the locomotive problem, based on a\n      uniform prior.</figcaption></figure>"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "The most likely value, if you had to guess, is 60. That might not seem like a very good guess; after all, what are the chances that you just happened to see the train with the highest number? Nevertheless, if you want to maximize the chance of getting the answer exactly right, you should guess 60."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "But maybe thatâs not the right goal. An alternative is to compute the mean of the posterior distribution:"
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "def Mean(suite):\n    total = 0\n    for hypo, prob in suite.Items():\n        total += hypo * prob\n    return total\n\nprint Mean(suite)",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "Or you could use the very similar method provided by `Pmf` :"
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "    print suite.Mean()",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "The mean of the posterior is 333, so that might be a good guess if you wanted to minimize error. If you played this guessing game over and over, using the mean of the posterior as your estimate would minimize the mean squared error over the long run (see [http://en.wikipedia.org/wiki/Minimum\\_mean\\_square\\_error](http://en.wikipedia.org/wiki/Minimum_mean_square_error))."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "You can download this example from [http://thinkbayes.com/train.py](http://thinkbayes.com/train.py). For more information see [âWorking with the codeâ](preface01.html#download)."
        },
        {
          "cell_type": "heading",
          "level": 2,
          "metadata": {
          },
          "source": "What about that prior?"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "To make any progress on the locomotive problem we had to make assumptions, and some of them were pretty arbitrary. In particular, we chose a uniform prior from 1 to 1000, without much justification for choosing 1000, or for choosing a uniform distribution."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "It is not crazy to believe that a railroad company might operate 1000 locomotives, but a reasonable person might guess more or fewer. So we might wonder whether the posterior distribution is sensitive to these assumptions. With so little dataâonly one observationâit probably is."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "Recall that with a uniform prior from 1 to 1000, the mean of the posterior is 333. With an upper bound of 500, we get a posterior mean of 207, and with an upper bound of 2000, the posterior mean is 552."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "So thatâs bad. There are two ways to proceed:"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "<ul>\n<li><p>Get more data.</p></li>\n<li><p>Get more background information.</p></li>\n</ul>\n"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "With more data, posterior distributions based on different priors tend to converge. For example, suppose that in addition to train 60 we also see trains 30 and 90. We can update the distribution like this:"
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "    for data in [60, 30, 90]:\n        suite.Update(data)",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "With these data, the means of the posteriors are"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "<table><tbody>\n<tr>\n<td><p>Upper </p></td>\n<td><p> Posterior </p></td>\n</tr>\n<tr>\n<td><p>Bound </p></td>\n<td><p> Mean </p></td>\n</tr>\n<tr>\n<td><p>500 </p></td>\n<td><p> 152 </p></td>\n</tr>\n<tr>\n<td><p>1000 </p></td>\n<td><p> 164</p></td>\n</tr>\n<tr>\n<td><p>2000 </p></td>\n<td><p> 171</p></td>\n</tr>\n</tbody></table>\n"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "So the differences are smaller."
        },
        {
          "cell_type": "heading",
          "level": 2,
          "metadata": {
          },
          "source": "An alternative prior"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "If more data are not available, another option is to improve the priors by gathering more background information. It is probably not reasonable to assume that a train-operating company with 1000 locomotives is just as likely as a company with only 1."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "With some effort, we could probably find a list of companies that operate locomotives in the area of observation. Or we could interview an expert in rail shipping to gather information about the typical size of companies."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "But even without getting into the specifics of railroad economics, we can make some educated guesses. In most fields, there are many small companies, fewer medium-sized companies, and only one or two very large companies. In fact, the distribution of company sizes tends to follow a power law, as Robert Axtell reports in _Science_ (see [http://www.sciencemag.org/content/293/5536/1818.full.pdf](http://www.sciencemag.org/content/293/5536/1818.full.pdf))."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "This law suggests that if there are 1000 companies with fewer than 10 locomotives, there might be 100 companies with 100 locomotives, 10 companies with 1000, and possibly one company with 10,000 locomotives."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "Mathematically, a power law means that the number of companies with a given size is inversely proportional to size, or"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "<div data-type=\"equation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mrow xmlns:mml=\"http://www.w3.org/1998/Math/MathML\"><mi>PMF</mi><mrow><mo>(</mo><mi>x</mi><mo>)</mo></mrow><mo>â</mo><msup><mfenced close=\")\" open=\"(\" separators=\"\"><mfrac><mn>1</mn><mi>x</mi></mfrac></mfenced><mi>Î±</mi></msup></mrow></math></div>\n"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "where PMF(x) is the probability mass function of _x_ and _Î±_ is a parameter that is often near 1."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "We can construct a power law prior like this:"
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "class Train(Dice):\n\n    def __init__(self, hypos, alpha=1.0):\n        Pmf.__init__(self)\n        for hypo in hypos:\n            self.Set(hypo, hypo**(-alpha))\n        self.Normalize()",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "And hereâs the code that constructs the prior:"
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "    hypos = range(1, 1001)\n    suite = Train(hypos)",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "Again, the upper bound is arbitrary, but with a power law prior, the posterior is less sensitive to this choice."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "FigureÂ 3-2 shows the new posterior based on the power law, compared to the posterior based on the uniform prior. Using the background information represented in the power law prior, we can all but eliminate values of _N_ greater than 700."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "<figure id=\"fig.train4\" style=\"float: True\"><img src=\"files/images/thba_0302.png\"><figcaption>Posterior distribution based on a power law prior, compared to a\n      uniform prior.</figcaption></figure>"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "If we start with this prior and observe trains 30, 60, and 90, the means of the posteriors are:"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "<table><tbody>\n<tr>\n<td><p> Upper </p></td>\n<td><p> Posterior </p></td>\n</tr>\n<tr>\n<td><p>Bound </p></td>\n<td><p> Mean </p></td>\n</tr>\n<tr>\n<td><p>500 </p></td>\n<td><p> 131 </p></td>\n</tr>\n<tr>\n<td><p>1000 </p></td>\n<td><p> 133 </p></td>\n</tr>\n<tr>\n<td><p>2000 </p></td>\n<td><p> 134 </p></td>\n</tr>\n</tbody></table>\n"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "Now the differences are much smaller. In fact, with an arbitrarily large upper bound, the mean converges on 134."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "So the power law prior is more realistic, because it is based on general information about the size of companies, and it behaves better in practice."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "You can download the examples in this section from [http://thinkbayes.com/train3.py](http://thinkbayes.com/train3.py). For more information see [âWorking with the codeâ](preface01.html#download)."
        },
        {
          "cell_type": "heading",
          "level": 2,
          "metadata": {
          },
          "source": "Credible intervals"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "Once you have computed a posterior distribution, it is often useful to summarize the results with a single point estimate or an interval. For point estimates it is common to use the mean, median, or the value with maximum likelihood."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "For intervals we usually report two values computed so that there is a 90% chance that the unknown value falls between them (or any other probability). These values define a **credible interval**."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "A simple way to compute a credible interval is to add up the probabilities in the posterior distribution and record the values that correspond to probabilities 5% and 95%. In other words, the 5th and 95th percentiles."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "`thinkbayes` provides a function that computes percentiles:"
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "def Percentile(pmf, percentage):\n    p = percentage / 100.0\n    total = 0\n    for val, prob in pmf.Items():\n        total += prob\n        if total >= p:\n            return val",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "And hereâs the code that uses it:"
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "    interval = Percentile(suite, 5), Percentile(suite, 95)\n    print interval",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "For the previous exampleâthe locomotive problem with a power law prior and three trainsâthe 90% credible interval is (91,243). The width of this range suggests, correctly, that we are still quite uncertain about how many locomotives there are."
        },
        {
          "cell_type": "heading",
          "level": 2,
          "metadata": {
          },
          "source": "Cumulative distribution functions"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "In the previous section we computed percentiles by iterating through the values and probabilities in a Pmf. If we need to compute more than a few percentiles, it is more efficient to use a cumulative distribution function, or Cdf."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "Cdfs and Pmfs are equivalent in the sense that they contain the same information about the distribution, and you can always convert from one to the other. The advantage of the Cdf is that you can compute percentiles more efficiently."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "`thinkbayes` provides a `Cdf` class that represents a cumulative distribution function. `Pmf` provides a method that makes the corresponding Cdf:"
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "cdf = suite.MakeCdf()",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "And `Cdf` provides a function named `Percentile`"
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "    interval = cdf.Percentile(5), cdf.Percentile(95)",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "Converting from a Pmf to a Cdf takes time proportional to the number of values, `len(pmf)` . The Cdf stores the values and probabilities in sorted lists, so looking up a probability to get the corresponding value takes âlog timeâ: that is, time proportional to the logarithm of the number of values. Looking up a value to get the corresponding probability is also logarithmic, so Cdfs are efficient for many calculations."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "The examples in this section are in [http://thinkbayes.com/train3.py](http://thinkbayes.com/train3.py). For more information see [âWorking with the codeâ](preface01.html#download)."
        },
        {
          "cell_type": "heading",
          "level": 2,
          "metadata": {
          },
          "source": "The German tank problem"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "During World War II, the Economic Warfare Division of the American Embassy in London used statistical analysis to estimate German production of tanks and other equipment. [2](ch03.html#idp1235248)"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "The Western Allies had captured log books, inventories, and repair records that included chassis and engine serial numbers for individual tanks."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "Analysis of these records indicated that serial numbers were allocated by manufacturer and tank type in blocks of 100 numbers, that numbers in each block were used sequentially, and that not all numbers in each block were used. So the problem of estimating German tank production could be reduced, within each block of 100 numbers, to a form of the locomotive problem."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "Based on this insight, American and British analysts produced estimates substantially lower than estimates from other forms of intelligence. And after the war, records indicated that they were substantially more accurate."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "They performed similar analyses for tires, trucks, rockets, and other equipment, yielding accurate and actionable economic intelligence."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "The German tank problem is historically interesting; it is also a nice example of real-world application of statistical estimation. So far many of the examples in this book have been toy problems, but it will not be long before we start solving real problems. I think it is an advantage of Bayesian analysis, especially with the computational approach we are taking, that it provides such a short path from a basic introduction to the research frontier."
        },
        {
          "cell_type": "heading",
          "level": 2,
          "metadata": {
          },
          "source": "Discussion"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "Among Bayesians, there are two approaches to choosing prior distributions. Some recommend choosing the prior that best represents background information about the problem; in that case the prior is said to be **informative**. The problem with using an informative prior is that people might use different background information (or interpret it differently). So informative priors often seem subjective."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "The alternative is a so-called **uninformative prior**, which is intended to be as unrestricted as possible, in order to let the data speak for themselves. In some cases you can identify a unique prior that has some desirable property, like representing minimal prior information about the estimated quantity."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "Uninformative priors are appealing because they seem more objective. But I am generally in favor of using informative priors. Why? First, Bayesian analysis is always based on modeling decisions. Choosing the prior is one of those decisions, but it is not the only one, and it might not even be the most subjective. So even if an uninformative prior is more objective, the entire analysis is still subjective."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "Also, for most practical problems, you are likely to be in one of two regimes: either you have a lot of data or not very much. If you have a lot of data, the choice of the prior doesnât matter very much; informative and uninformative priors yield almost the same results. Weâll see an example like this in the next chapter."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "But if, as in the locomotive problem, you donât have much data, using relevant background information (like the power law distribution) makes a big difference."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "And if, as in the German tank problem, you have to make life-and-death decisions based on your results, you should probably use all of the information at your disposal, rather than maintaining the illusion of objectivity by pretending to know less than you do."
        },
        {
          "cell_type": "heading",
          "level": 2,
          "metadata": {
          },
          "source": "Exercises"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "<div id=\"a0000001555\" class=\"exercise\" data-type=\"example\">\n<h5></h5>\n<p>To write a likelihood function for the locomotive problem, we\n        had to answer this question: âIf the railroad has <em>N</em> locomotives, what is the probability that we\n        see number 60?â</p>\n<p>The answer depends on what sampling process we use when we\n        observe the locomotive. In this chapter, I resolved the ambiguity by\n        specifying that there is only one train-operating company (or only one\n        that we care about).</p>\n<p>But suppose instead that there are many companies with different\n        numbers of trains. And suppose that you are equally likely to see any\n        train operated by any company. In that case, the likelihood function\n        is different because you are more likely to see a train operated by a\n        large company.</p>\n<p>As an exercise, implement the likelihood function for this\n        variation of the locomotive problem, and compare the results.</p>\n</div>"
        }
      ],
      "metadata": {
      }
    }
  ]
}