{
  "metadata": {
    "name": "Two Dimensions"
  },
  "nbformat": 3,
  "nbformat_minor": 0,
  "worksheets": [
    {
      "cells": [
        {
          "cell_type": "heading",
          "level": 1,
          "metadata": {
          },
          "source": "Two Dimensions"
        },
        {
          "cell_type": "heading",
          "level": 2,
          "metadata": {
          },
          "source": "Paintball"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "Paintball is a sport in which competing teams try to shoot each other with guns that fire paint-filled pellets that break on impact, leaving a colorful mark on the target. It is usually played in an arena decorated with barriers and other objects that can be used as cover."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "Suppose you are playing paintball in an indoor arena 30 feet wide and 50 feet long. You are standing near one of the 30 foot walls, and you suspect that one of your opponents has taken cover nearby. Along the wall, you see several paint spatters, all the same color, that you think your opponent fired recently."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "The spatters are at 15, 16, 18, and 21 feet, measured from the lower-left corner of the room. Based on these data, where do you think your opponent is hiding?"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "FigureÂ 9-1 shows a diagram of the arena. Using the lower-left corner of the room as the origin, I denote the unknown location of the shooter with coordinates _Î±_ and _Î²_, or `alpha` and `beta` . The location of a spatter is labeled `x` . The angle the opponent shoots at is _Î¸_ or `theta` ."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "The Paintball problem is a modified version of the Lighthouse problem, a common example of Bayesian analysis. My notation follows the presentation of the problem in D.S. Siviaâs, _Data Analysis: a Bayesian Tutorial, Second Edition_ (Oxford, 2006)."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "You can download the code in this chapter from [http://thinkbayes.com/paintball.py](http://thinkbayes.com/paintball.py). For more information see [âWorking with the codeâ](preface01.html#download)."
        },
        {
          "cell_type": "heading",
          "level": 2,
          "metadata": {
          },
          "source": "The suite"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "<figure id=\"fig.paintball\" style=\"float: True\"><img src=\"files/images/thba_0901.png\"><figcaption>Diagram of the layout for the paintball problem.</figcaption></figure>"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "To get started, we need a Suite that represents a set of hypotheses about the location of the opponent. Each hypothesis is a pair of coordinates: `(alpha, beta)` ."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "Here is the definition of the Paintball suite:"
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "class Paintball(thinkbayes.Suite, thinkbayes.Joint):\n\n    def __init__(self, alphas, betas, locations):\n        self.locations = locations\n        pairs = [(alpha, beta) \n                 for alpha in alphas \n                 for beta in betas]\n        thinkbayes.Suite.__init__(self, pairs)",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "`Paintball` inherits from `Suite` , which we have seen before, and `Joint` , which I will explain soon."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "`alphas` is the list of possible values for `alpha` ; `betas` is the list of values for `beta` . `pairs` is a list of all `(alpha, beta)` pairs."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "`locations` is a list of possible locations along the wall; it is stored for use in `Likelihood` ."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "The room is 30 feet wide and 50 feet long, so hereâs the code that creates the suite:"
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "    alphas = range(0, 31)\n    betas = range(1, 51)\n    locations = range(0, 31)\n\n    suite = Paintball(alphas, betas, locations)",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "This prior distribution assumes that all locations in the room are equally likely. Given a map of the room, we might choose a more detailed prior, but weâll start simple."
        },
        {
          "cell_type": "heading",
          "level": 2,
          "metadata": {
          },
          "source": "Trigonometry"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "Now we need a likelihood function, which means we have to figure out the likelihood of hitting any spot along the wall, given the location of the opponent."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "As a simple model, imagine that the opponent is like a rotating turret, equally likely to shoot in any direction. In that case, he is most likely to hit the wall at location `alpha` , and less likely to hit the wall far away from `alpha` ."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "With a little trigonometry, we can compute the probability of hitting any spot along the wall. Imagine that the shooter fires a shot at angle _Î¸_; the pellet would hit the wall at location _x_, where"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "<div data-type=\"equation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mrow xmlns:mml=\"http://www.w3.org/1998/Math/MathML\"><mi>x</mi><mo>-</mo><mi>Î±</mi><mo>=</mo><mi>Î²</mi><mo form=\"prefix\">tan</mo><mi>Î¸</mi></mrow></math></div>\n"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "Solving this equation for _Î¸_ yields"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "<div data-type=\"equation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mrow xmlns:mml=\"http://www.w3.org/1998/Math/MathML\"><mi>Î¸</mi><mo>=</mo><mi>t</mi><mi>a</mi><msup><mi>n</mi><mrow><mo>-</mo><mn>1</mn></mrow></msup><mfenced close=\")\" open=\"(\" separators=\"\"><mfrac><mrow><mi>x</mi><mo>-</mo><mi>Î±</mi></mrow><mi>Î²</mi></mfrac></mfenced></mrow></math></div>\n"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "So given a location on the wall, we can find _Î¸_."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "Taking the derivative of the first equation with respect to _Î¸_ yields"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "<div data-type=\"equation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mrow xmlns:mml=\"http://www.w3.org/1998/Math/MathML\"><mfrac><mrow><mi>d</mi><mi>x</mi></mrow><mrow><mi>d</mi><mi>Î¸</mi></mrow></mfrac><mo>=</mo><mfrac><mi>Î²</mi><mrow><msup><mo form=\"prefix\">cos</mo><mn>2</mn></msup><mi>Î¸</mi></mrow></mfrac></mrow></math></div>\n"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "This derivative is what Iâll call the âstrafing speedâ, which is the speed of the target location along the wall as _Î¸_ increases. The probability of hitting a given point on the wall is inversely related to strafing speed."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "If we know the coordinates of the shooter and a location along the wall, we can compute strafing speed:"
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "def StrafingSpeed(alpha, beta, x):\n    theta = math.atan2(x - alpha, beta)\n    speed = beta / math.cos(theta)**2\n    return speed",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "`alpha` and `beta` are the coordinates of the shooter; `x` is the location of a spatter. The result is the derivative of `x` with respect to `theta` ."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "Now we can compute a Pmf that represents the probability of hitting any location on the wall. `MakeLocationPmf` takes `alpha` and `beta` , the coordinates of the shooter, and `locations` , a list of possible values of `x` ."
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "def MakeLocationPmf(alpha, beta, locations):\n    pmf = thinkbayes.Pmf()\n    for x in locations:\n        prob = 1.0 / StrafingSpeed(alpha, beta, x)\n        pmf.Set(x, prob)\n    pmf.Normalize()\n    return pmf",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "`MakeLocationPmf` computes the probability of hitting each location, which is inversely related to strafing speed. The result is a Pmf of locations and their probabilities."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "FigureÂ 9-2 shows the Pmf of location with `alpha = 10` and a range of values for `beta` . For all values of beta the most likely spatter location is `x = 10` ; as `beta` increases, so does the spread of the Pmf."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "<figure id=\"fig.paintball1\" style=\"float: none\"><img src=\"files/images/thba_0903.png\"><figcaption>PMF of location given alpha=10, for several values of\n      beta.</figcaption></figure>"
        },
        {
          "cell_type": "heading",
          "level": 2,
          "metadata": {
          },
          "source": "Likelihood"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "Now all we need is a likelihood function. We can use `MakeLocationPmf` to compute the likelihood of any value of `x` , given the coordinates of the opponent."
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "    def Likelihood(self, data, hypo):\n        alpha, beta = hypo\n        x = data\n        pmf = MakeLocationPmf(alpha, beta, self.locations)\n        like = pmf.Prob(x)\n        return like",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "Again, `alpha` and `beta` are the hypothetical coordinates of the shooter, and `x` is the location of an observed spatter."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "`pmf` contains the probability of each location, given the coordinates of the shooter. From this Pmf, we select the probability of the observed location."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "And weâre done. To update the suite, we can use `UpdateSet` , which is inherited from `Suite` ."
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "suite.UpdateSet([15, 16, 18, 21])",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "The result is a distribution that maps each `(alpha, beta)` pair to a posterior probability."
        },
        {
          "cell_type": "heading",
          "level": 2,
          "metadata": {
          },
          "source": "Joint distributions"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "When each value in a distribution is a tuple of variables, it is called a **joint distribution** because it represents the distributions of the variables together, that is âjointlyâ. A joint distribution contains the distributions of the variables, as well information about the relationships among them."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "Given a joint distribution, we can compute the distributions of each variable independently, which are called the **marginal distributions**."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "`thinkbayes.Joint` provides a method that computes marginal distributions:"
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "# class Joint:\n\n    def Marginal(self, i):\n        pmf = Pmf()\n        for vs, prob in self.Items():\n            pmf.Incr(vs[i], prob)\n        return pmf",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "`i` is the index of the variable we want; in this example `i=0` indicates the distribution of `alpha` , and `i=1` indicates the distribution of `beta` ."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "Hereâs the code that extracts the marginal distributions:"
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "    marginal_alpha = suite.Marginal(0)\n    marginal_beta = suite.Marginal(1)",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "FigureÂ 9-3 shows the results (converted to CDFs). The median value for `alpha` is 18, near the center of mass of the observed spatters. For `beta` , the most likely values are close to the wall, but beyond 10 feet the distribution is almost uniform, which indicates that the data do not distinguish strongly between these possible locations."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "<figure id=\"fig.paintball2\" style=\"float: none\"><img src=\"files/images/thba_0902.png\"><figcaption>Posterior CDFs for alpha and beta, given the data.</figcaption></figure>"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "Given the posterior marginals, we can compute credible intervals for each coordinate independently:"
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "    print 'alpha CI', marginal_alpha.CredibleInterval(50)\n    print 'beta CI', marginal_beta.CredibleInterval(50)",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "The 50% credible intervals are `(14,\n        21)`  for  `alpha`  and  `(5, 31)`  for  `beta` . So the data provide evidence that the shooter is in the near side of the room. But it is not strong evidence. The 90% credible intervals cover most of the room! "
        },
        {
          "cell_type": "heading",
          "level": 2,
          "metadata": {
          },
          "source": "Conditional distributions"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "The marginal distributions contain information about the variables independently, but they do not capture the dependence between variables, if any."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "One way to visualize dependence is by computing **conditional distributions**. `thinkbayes.Joint` provides a method that does that:"
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "    def Conditional(self, i, j, val):\n        pmf = Pmf()\n        for vs, prob in self.Items():\n            if vs[j] != val: continue\n            pmf.Incr(vs[i], prob)\n\n        pmf.Normalize()\n        return pmf",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "Again, `i` is the index of the variable we want; `j` is the index of the conditioning variable, and `val` is the conditional value."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "The result is the distribution of the _i_th variable under the condition that the _j_th variable is `val` ."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "For example, the following code computes the conditional distributions of `alpha` for a range of values of `beta` :"
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "    betas = [10, 20, 40]\n\n    for beta in betas:\n        cond = suite.Conditional(0, 1, beta)",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "FigureÂ 9-4 shows the results, which we could fully describe as âposterior conditional marginal distributions.â Whew!"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "<figure id=\"fig.paintball3\" style=\"float: True\"><img src=\"files/images/thba_0904.png\"><figcaption>Posterior distributions for alpha conditioned on several values\n      of beta.</figcaption></figure>"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "If the variables were independent, the conditional distributions would all be the same. Since they are all different, we can tell the variables are dependent. For example, if we know (somehow) that `beta = 10` , the conditional distribution of `alpha` is fairly narrow. For larger values of `beta` , the distribution of `alpha` is wider."
        },
        {
          "cell_type": "heading",
          "level": 2,
          "metadata": {
          },
          "source": "Credible intervals"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "Another way to visualize the posterior joint distribution is to compute credible intervals. When we looked at credible intervals in [âCredible intervalsâ](ch03.html#credible), I skipped over a subtle point: for a given distribution, there are many intervals with the same level of credibility. For example, if you want a 50% credible interval, you could choose any set of values whose probability adds up to 50%."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "When the values are one-dimensional, it is most common to choose the **central credible interval**; for example, the central 50% credible interval contains all values between the 25th and 75th percentiles."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "In multiple dimensions it is less obvious what the right credible interval should be. The best choice might depend on context, but one common choice is the maximum likelihood credible interval, which contains the most likely values that add up to 50% (or some other percentage)."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "`thinkbayes.Joint` provides a method that computes maximum likelihood credible intervals."
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "# class Joint:\n\n    def MaxLikeInterval(self, percentage=90):\n        interval = []\n        total = 0\n\n        t = [(prob, val) for val, prob in self.Items()]\n        t.sort(reverse=True)\n\n        for prob, val in t:\n            interval.append(val)\n            total += prob\n            if total >= percentage/100.0:\n                break\n\n        return interval",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "The first step is to make a list of the values in the suite, sorted in descending order by probability. Next we traverse the list, adding each value to the interval, until the total probability exceeds `percentage` . The result is a list of values from the suite. Notice that this set of values is not necessarily contiguous."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "To visualize the intervals, I wrote a function that âcolorsâ each value according to how many intervals it appears in:"
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "def MakeCrediblePlot(suite):\n    d = dict((pair, 0) for pair in suite.Values())\n\n    percentages = [75, 50, 25]\n    for p in percentages:\n        interval = suite.MaxLikeInterval(p)\n        for pair in interval:\n            d[pair] += 1\n\n    return d",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "`d` is a dictionary that maps from each value in the suite to the number of intervals it appears in. The loop computes intervals for several percentages and modifies `d` ."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "FigureÂ 9-5 shows the result. The 25% credible interval is the darkest region near the bottom wall. For higher percentages, the credible interval is bigger, of course, and skewed toward the right side of the room."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "<figure id=\"fig.paintball5\" style=\"float: True\"><img src=\"files/images/thba_0905.png\"><figcaption>Credible intervals for the coordinates of the opponent.</figcaption></figure>"
        },
        {
          "cell_type": "heading",
          "level": 2,
          "metadata": {
          },
          "source": "Discussion"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "This chapter shows that the Bayesian framework from the previous chapters can be extended to handle a two-dimensional parameter space. The only difference is that each hypothesis is represented by a tuple of parameters."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "I also presented `Joint` , which is a parent class that provides methods that apply to joint distributions: `Marginal` , `Conditional` , and `MakeLikeInterval` . In object-oriented terms, `Joint` is a mixin (see [http://en.wikipedia.org/wiki/Mixin](http://en.wikipedia.org/wiki/Mixin))."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "There is a lot of new vocabulary in this chapter, so letâs review:"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "Given the joint distribution, you can compute marginal and conditional distributions. With enough conditional distributions, you could re-create the joint distribution, at least approximately. But given the marginal distributions you cannot re-create the joint distribution because you have lost information about the dependence between variables."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "If there are _n_ possible values for each of two parameters, most operations on the joint distribution take time proportional to _n2_. If there are _d_ parameters, run time is proportional to _nd_, which quickly becomes impractical as the number of dimensions increases."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "If you can process a million hypotheses in a reasonable amount of time, you could handle two dimensions with 1000 values for each parameter, or three dimensions with 100 values each, or six dimensions with 10 values each."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "If you need more dimensions, or more values per dimension, there are optimizations you can try. I present an example in [ChapterÂ 15](ch15.html#species)."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "You can download the code in this chapter from [http://thinkbayes.com/paintball.py](http://thinkbayes.com/paintball.py). For more information see [âWorking with the codeâ](preface01.html#download)."
        },
        {
          "cell_type": "heading",
          "level": 2,
          "metadata": {
          },
          "source": "Exercises"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "<div id=\"a0000004244\" class=\"exercise\" data-type=\"example\">\n<h5></h5>\n<p>In our simple model, the opponent is equally likely to shoot in\n        any direction. As an exercise, letâs consider improvements to this\n        model.</p>\n<p>The analysis in this chapter suggests that a shooter is most\n        likely to hit the closest wall. But in reality, if the opponent is\n        close to a wall, he is unlikely to shoot at the wall because he is\n        unlikely to see a target between himself and the wall.</p>\n<p>Design an improved model that takes this behavior into account.\n        Try to find a model that is more realistic, but not too\n        complicated.</p>\n</div>"
        }
      ],
      "metadata": {
      }
    }
  ]
}