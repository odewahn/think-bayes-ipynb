{
  "metadata": {
    "name": "Odds and Addends"
  },
  "nbformat": 3,
  "nbformat_minor": 0,
  "worksheets": [
    {
      "cells": [
        {
          "cell_type": "heading",
          "level": 1,
          "metadata": {
          },
          "source": "Odds and Addends"
        },
        {
          "cell_type": "heading",
          "level": 2,
          "metadata": {
          },
          "source": "Odds"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "One way to represent a probability is with a number between 0 and 1, but thatâs not the only way. If you have ever bet on a football game or a horse race, you have probably encountered another representation of probability, called **odds**."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "You might have heard expressions like âthe odds are three to one,â but you might not know what they mean. The **odds in favor** of an event are the ratio of the probability it will occur to the probability that it will not."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "So if I think my team has a 75% chance of winning, I would say that the odds in their favor are three to one, because the chance of winning is three times the chance of losing."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "You can write odds in decimal form, but it is most common to write them as a ratio of integers. So âthree to oneâ is written 3:1."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "When probabilities are low, it is more common to report the **odds against** rather than the odds in favor. For example, if I think my horse has a 10% chance of winning, I would say that the odds against are 9:1."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "Probabilities and odds are different representations of the same information. Given a probability, you can compute the odds like this:"
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "def Odds(p):\n    return p / (1-p)",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "Given the odds in favor, in decimal form, you can convert to probability like this:"
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "def Probability(o):\n    return o / (o+1)",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "If you represent odds with a numerator and denominator, you can convert to probability like this:"
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "def Probability2(yes, no):\n    return yes / (yes + no)",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "When I work with odds in my head, I find it helpful to picture people at the track. If 20% of them think my horse will win, then 80% of them donât, so the odds in favor are 20:80 or 1:4."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "If the odds are 5:1 against my horse, then five out of six people think she will lose, so the probability of winning is 1/6."
        },
        {
          "cell_type": "heading",
          "level": 2,
          "metadata": {
          },
          "source": "The odds form of Bayesâs theorem"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "In [ChapterÂ 1](ch01.html#intro) I wrote Bayesâs theorem in the **probability form**:"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "<div data-type=\"equation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mrow xmlns:mml=\"http://www.w3.org/1998/Math/MathML\"><mi mathvariant=\"normal\">p</mi><mrow><mo>(</mo><mi>H</mi><mo>|</mo><mi>D</mi><mo>)</mo></mrow><mo>=</mo><mfrac><mrow><mi mathvariant=\"normal\">p</mi><mo>(</mo><mi>H</mi><mo>)</mo><mspace width=\"3.33333pt\"></mspace><mi mathvariant=\"normal\">p</mi><mo>(</mo><mi>D</mi><mo>|</mo><mi>H</mi><mo>)</mo></mrow><mrow><mi mathvariant=\"normal\">p</mi><mo>(</mo><mi>D</mi><mo>)</mo></mrow></mfrac></mrow></math></div>\n"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "If we have two hypotheses, _A_ and _B_, we can write the ratio of posterior probabilities like this:"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "<div data-type=\"equation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mrow xmlns:mml=\"http://www.w3.org/1998/Math/MathML\"><mfrac><mrow><mi mathvariant=\"normal\">p</mi><mo>(</mo><mi>A</mi><mo>|</mo><mi>D</mi><mo>)</mo></mrow><mrow><mi mathvariant=\"normal\">p</mi><mo>(</mo><mi>B</mi><mo>|</mo><mi>D</mi><mo>)</mo></mrow></mfrac><mo>=</mo><mfrac><mrow><mi mathvariant=\"normal\">p</mi><mo>(</mo><mi>A</mi><mo>)</mo><mspace width=\"3.33333pt\"></mspace><mi mathvariant=\"normal\">p</mi><mo>(</mo><mi>D</mi><mo>|</mo><mi>A</mi><mo>)</mo></mrow><mrow><mi mathvariant=\"normal\">p</mi><mo>(</mo><mi>B</mi><mo>)</mo><mspace width=\"3.33333pt\"></mspace><mi mathvariant=\"normal\">p</mi><mo>(</mo><mi>D</mi><mo>|</mo><mi>B</mi><mo>)</mo></mrow></mfrac></mrow></math></div>\n"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "Notice that the normalizing constant, p(D), drops out of this equation."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "If _A_ and _B_ are mutually exclusive and collectively exhaustive, that means p(B)=1-p(A), so we can rewrite the ratio of the priors, and the ratio of the posteriors, as odds."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "Writing o(A) for odds in favor of _A_, we get:"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "<div data-type=\"equation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mrow xmlns:mml=\"http://www.w3.org/1998/Math/MathML\"><mi mathvariant=\"normal\">o</mi><mrow><mo>(</mo><mi>A</mi><mo>|</mo><mi>D</mi><mo>)</mo></mrow><mo>=</mo><mi mathvariant=\"normal\">o</mi><mrow><mo>(</mo><mi>A</mi><mo>)</mo></mrow><mspace width=\"3.33333pt\"></mspace><mfrac><mrow><mi mathvariant=\"normal\">p</mi><mo>(</mo><mi>D</mi><mo>|</mo><mi>A</mi><mo>)</mo></mrow><mrow><mi mathvariant=\"normal\">p</mi><mo>(</mo><mi>D</mi><mo>|</mo><mi>B</mi><mo>)</mo></mrow></mfrac></mrow></math></div>\n"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "In words, this says that the posterior odds are the prior odds times the likelihood ratio. This is the **odds form** of Bayesâs theorem."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "This form is most convenient for computing a Bayesian update on paper or in your head. For example, letâs go back to the cookie problem:"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "<blockquote>\n<p>Suppose there are two bowls of cookies. Bowl 1 contains 30 vanilla\n      cookies and 10 chocolate cookies. Bowl 2 contains 20 of each.</p>\n<p>Now suppose you choose one of the bowls at random and, without\n      looking, select a cookie at random. The cookie is vanilla. What is the\n      probability that it came from Bowl 1?</p>\n</blockquote>\n"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "The prior probability is 50%, so the prior odds are 1:1, or just 1. The likelihood ratio is 34/12, or 3/2. So the posterior odds are 3:2, which corresponds to probability 3/5."
        },
        {
          "cell_type": "heading",
          "level": 2,
          "metadata": {
          },
          "source": "Oliverâs blood"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "Here is another problem from MacKayâs _Information Theory, Inference, and Learning Algorithms_:"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "<blockquote><p>Two people have left traces of their own blood at the scene of a\n      crime. A suspect, Oliver, is tested and found to have type âOâ blood.\n      The blood groups of the two traces are found to be of type âOâ (a common\n      type in the local population, having frequency 60%) and of type âABâ (a\n      rare type, with frequency 1%). Do these data [the traces found at the\n      scene] give evidence in favor of the proposition that Oliver was one of\n      the people [who left blood at the scene]?</p></blockquote>\n"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "To answer this question, we need to think about what it means for data to give evidence in favor of (or against) a hypothesis. Intuitively, we might say that data favor a hypothesis if the hypothesis is more likely in light of the data than it was before."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "In the cookie problem, the prior odds are 1:1, or probability 50%. The posterior odds are 3:2, or probability 60%. So we could say that the vanilla cookie is evidence in favor of Bowl 1."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "The odds form of Bayesâs theorem provides a way to make this intuition more precise. Again"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "<div data-type=\"equation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mrow xmlns:mml=\"http://www.w3.org/1998/Math/MathML\"><mi mathvariant=\"normal\">o</mi><mrow><mo>(</mo><mi>A</mi><mo>|</mo><mi>D</mi><mo>)</mo></mrow><mo>=</mo><mi mathvariant=\"normal\">o</mi><mrow><mo>(</mo><mi>A</mi><mo>)</mo></mrow><mspace width=\"3.33333pt\"></mspace><mfrac><mrow><mi mathvariant=\"normal\">p</mi><mo>(</mo><mi>D</mi><mo>|</mo><mi>A</mi><mo>)</mo></mrow><mrow><mi mathvariant=\"normal\">p</mi><mo>(</mo><mi>D</mi><mo>|</mo><mi>B</mi><mo>)</mo></mrow></mfrac></mrow></math></div>\n"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "Or dividing through by o(A):"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "<div data-type=\"equation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mrow xmlns:mml=\"http://www.w3.org/1998/Math/MathML\"><mfrac><mrow><mi mathvariant=\"normal\">o</mi><mo>(</mo><mi>A</mi><mo>|</mo><mi>D</mi><mo>)</mo></mrow><mrow><mi mathvariant=\"normal\">o</mi><mo>(</mo><mi>A</mi><mo>)</mo></mrow></mfrac><mo>=</mo><mfrac><mrow><mi mathvariant=\"normal\">p</mi><mo>(</mo><mi>D</mi><mo>|</mo><mi>A</mi><mo>)</mo></mrow><mrow><mi mathvariant=\"normal\">p</mi><mo>(</mo><mi>D</mi><mo>|</mo><mi>B</mi><mo>)</mo></mrow></mfrac></mrow></math></div>\n"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "The term on the left is the ratio of the posterior and prior odds. The term on the right is the likelihood ratio, also called the **Bayes factor**."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "If the Bayes factor value is greater than 1, that means that the data were more likely under _A_ than under _B_. And since the odds ratio is also greater than 1, that means that the odds are greater, in light of the data, than they were before."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "If the Bayes factor is less than 1, that means the data were less likely under _A_ than under _B_, so the odds in favor of _A_ go down."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "Finally, if the Bayes factor is exactly 1, the data are equally likely under either hypothesis, so the odds do not change."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "Now we can get back to the Oliverâs blood problem. If Oliver is one of the people who left blood at the crime scene, then he accounts for the âOâ sample, so the probability of the data is just the probability that a random member of the population has type âABâ blood, which is 1%."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "If Oliver did not leave blood at the scene, then we have two samples to account for. If we choose two random people from the population, what is the chance of finding one with type âOâ and one with type âABâ? Well, there are two ways it might happen: the first person we choose might have type âOâ and the second âABâ, or the other way around. So the total probability is 2(0.6)(0.01)=1.2%."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "The likelihood of the data is slightly higher if Oliver is _not_ one of the people who left blood at the scene, so the blood data is actually evidence against Oliverâs guilt."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "This example is a little contrived, but it is an example of the counterintuitive result that data _consistent_ with a hypothesis are not necessarily _in favor of_ the hypothesis."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "If this result is so counterintuitive that it bothers you, this way of thinking might help: the data consist of a common event, type âOâ blood, and a rare event, type âABâ blood. If Oliver accounts for the common event, that leaves the rare event still unexplained. If Oliver doesnât account for the âOâ blood, then we have two chances to find someone in the population with âABâ blood. And that factor of two makes the difference."
        },
        {
          "cell_type": "heading",
          "level": 2,
          "metadata": {
          },
          "source": "Addends"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "The fundamental operation of Bayesian statistics is `Update` , which takes a prior distribution and a set of data, and produces a posterior distribution. But solving real problems usually involves a number of other operations, including scaling, addition and other arithmetic operations, max and min, and mixtures."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "This chapter presents addition and max; I will present other operations as we need them."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "The first example is based on _Dungeons&Dragons_, a role-playing game where the results of playersâ decisions are usually determined by rolling dice. In fact, before game play starts, players generate each attribute of their charactersâstrength, intelligence, wisdom, dexterity, constitution, and charismaâby rolling three 6-sided dice and adding them up."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "So you might be curious to know the distribution of this sum. There are two ways you might compute it:"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "`thinkbayes` provides functions for both. Hereâs an example of the first approach. First, Iâll define a class to represent a single die as a Pmf:"
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "class Die(thinkbayes.Pmf):\n\n    def __init__(self, sides):\n        thinkbayes.Pmf.__init__(self)\n        for x in xrange(1, sides+1):\n            self.Set(x, 1)\n        self.Normalize()",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "Now I can create a 6-sided die:"
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "d6 = Die(6)",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "And use `thinkbayes.SampleSum` to generate a sample of 1000 rolls."
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "dice = [d6] * 3\nthree = thinkbayes.SampleSum(dice, 1000)",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "`SampleSum` takes list of distributions (either Pmf or Cdf objects) and the sample size, `n` . It generates `n` random sums and returns their distribution as a Pmf object."
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "def SampleSum(dists, n):\n    pmf = MakePmfFromList(RandomSum(dists) for i in xrange(n))\n    return pmf",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "`SampleSum` uses `RandomSum` , also in `thinkbayes.py` :"
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "def RandomSum(dists):\n    total = sum(dist.Random() for dist in dists)\n    return total",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "`RandomSum` invokes `Random` on each distribution and adds up the results."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "The drawback of simulation is that the result is only approximately correct. As `n` gets larger, it gets more accurate, but of course the run time increases as well."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "The other approach is to enumerate all pairs of values and compute the sum and probability of each pair. This is implemented in `Pmf.__add__` :"
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "# class Pmf\n\n    def __add__(self, other):\n        pmf = Pmf()\n        for v1, p1 in self.Items():\n            for v2, p2 in other.Items():\n                pmf.Incr(v1+v2, p1*p2)\n        return pmf",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "`self` is a Pmf, of course; `other` can be a Pmf or anything else that provides `Items` . The result is a new Pmf. The time to run `__add__` depends on the number of items in `self` and other; it is proportional to `len(self) * len(other)` ."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "And hereâs how itâs used:"
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "    three_exact = d6 + d6 + d6",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "When you apply the `+` operator to a Pmf, Python invokes `__add__` . In this example, `__add__` is invoked twice."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "FigureÂ 5-1 shows an approximate result generated by simulation and the exact result computed by enumeration."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "<figure id=\"fig.dungeons1\" style=\"float: none\"><img src=\"files/images/thba_0501.png\"><figcaption>Approximate and exact distributions for the sum of three 6-sided\n      dice.</figcaption></figure>"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "`Pmf.__add__` is based on the assumption that the random selections from each Pmf are independent. In the example of rolling several dice, this assumption is pretty good. In other cases, we would have to extend this method to use conditional probabilities."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "The code from this section is available from [http://thinkbayes.com/dungeons.py](http://thinkbayes.com/dungeons.py). For more information see [âWorking with the codeâ](preface01.html#download)."
        },
        {
          "cell_type": "heading",
          "level": 2,
          "metadata": {
          },
          "source": "Maxima"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "When you generate a _Dungeons&Dragons_ character, you are particularly interested in the characterâs best attributes, so you might like to know the distribution of the maximum attribute."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "There are three ways to compute the distribution of a maximum:"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "The code to simulate maxima is almost identical to the code for simulating sums:"
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "def RandomMax(dists):\n    total = max(dist.Random() for dist in dists)\n    return total\n\ndef SampleMax(dists, n):\n    pmf = MakePmfFromList(RandomMax(dists) for i in xrange(n))\n    return pmf",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "All I did was replace âsumâ with âmaxâ. And the code for enumeration is almost identical, too:"
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "def PmfMax(pmf1, pmf2):\n    res = thinkbayes.Pmf()\n    for v1, p1 in pmf1.Items():\n        for v2, p2 in pmf2.Items():\n            res.Incr(max(v1, v2), p1*p2)\n    return res",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "In fact, you could generalize this function by taking the appropriate operator as a parameter."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "The only problem with this algorithm is that if each Pmf has _m_ values, the run time is proportional to _m2_. And if we want the maximum of `k` selections, it takes time proportional to km2."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "If we convert the Pmfs to Cdfs, we can do the same calculation much faster! The key is to remember the definition of the cumulative distribution function:"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "<div data-type=\"equation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mrow xmlns:mml=\"http://www.w3.org/1998/Math/MathML\"><mi>C</mi><mi>D</mi><mi>F</mi><mo>(</mo><mi>x</mi><mo>)</mo><mo>=</mo><mi mathvariant=\"normal\">p</mi><mo>(</mo><mi>X</mi><mo>â¤</mo><mspace width=\"3.33333pt\"></mspace><mi>x</mi><mo>)</mo></mrow></math></div>\n"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "where _X_ is a random variable that means âa value chosen randomly from this distribution.â So, for example, CDF(5) is the probability that a value from this distribution is less than or equal to 5."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "If I draw _X_ from _CDF1_ and _Y_ from _CDF2_, and compute the maximum Z=max(X,Y), what is the chance that _Z_ is less than or equal to 5? Well, in that case both _X_ and _Y_ must be less than or equal to 5."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "If the selections of _X_ and _Y_ are independent,"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "<div data-type=\"equation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mrow xmlns:mml=\"http://www.w3.org/1998/Math/MathML\"><mi>C</mi><mi>D</mi><msub><mi>F</mi><mn>3</mn></msub><mrow><mo>(</mo><mn>5</mn><mo>)</mo></mrow><mo>=</mo><mi>C</mi><mi>D</mi><msub><mi>F</mi><mn>1</mn></msub><mrow><mo>(</mo><mn>5</mn><mo>)</mo></mrow><mi>C</mi><mi>D</mi><msub><mi>F</mi><mn>2</mn></msub><mrow><mo>(</mo><mn>5</mn><mo>)</mo></mrow></mrow></math></div>\n"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "where _CDF3_ is the distribution of _Z_. I chose the value 5 because I think it makes the formulas easy to read, but we can generalize for any value of _z_:"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "<div data-type=\"equation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mrow xmlns:mml=\"http://www.w3.org/1998/Math/MathML\"><mi>C</mi><mi>D</mi><msub><mi>F</mi><mn>3</mn></msub><mrow><mo>(</mo><mi>z</mi><mo>)</mo></mrow><mo>=</mo><mi>C</mi><mi>D</mi><msub><mi>F</mi><mn>1</mn></msub><mrow><mo>(</mo><mi>z</mi><mo>)</mo></mrow><mi>C</mi><mi>D</mi><msub><mi>F</mi><mn>2</mn></msub><mrow><mo>(</mo><mi>z</mi><mo>)</mo></mrow></mrow></math></div>\n"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "In the special case where we draw _k_ values from the same distribution,"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "<div data-type=\"equation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mrow xmlns:mml=\"http://www.w3.org/1998/Math/MathML\"><mi>C</mi><mi>D</mi><msub><mi>F</mi><mi>k</mi></msub><mrow><mo>(</mo><mi>z</mi><mo>)</mo></mrow><mo>=</mo><mi>C</mi><mi>D</mi><msub><mi>F</mi><mn>1</mn></msub><msup><mrow><mo>(</mo><mi>z</mi><mo>)</mo></mrow><mi>k</mi></msup></mrow></math></div>\n"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "So to find the distribution of the maximum of _k_ values, we can enumerate the probabilities in the given Cdf and raise them to the _k_th power. `Cdf` provides a method that does just that:"
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "# class Cdf\n\n    def Max(self, k):\n        cdf = self.Copy()\n        cdf.ps = [p**k for p in cdf.ps]\n        return cdf",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "`Max` takes the number of selections, `k` , and returns a new Cdf that represents the distribution of the maximum of `k` selections. The run time for this method is proportional to _m_, the number of items in the Cdf."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "`Pmf.Max` does the same thing for Pmfs. It has to do a little more work to convert the Pmf to a Cdf, so the run time is proportional to mlogm, but thatâs still better than quadratic."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "Finally, hereâs an example that computes the distribution of a characterâs best attribute:"
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "    best_attr_cdf = three_exact.Max(6)\n    best_attr_pmf = best_attr_cdf.MakePmf()",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "Where `three_exact` is defined in the previous section. If we print the results, we see that the chance of generating a character with at least one attribute of 18 is about 3%. FigureÂ 5-2 shows the distribution."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "<figure id=\"fig.dungeons2\" style=\"float: none\"><img src=\"files/images/thba_0502.png\"><figcaption>Distribution of the maximum of six rolls of three dice.</figcaption></figure>"
        },
        {
          "cell_type": "heading",
          "level": 2,
          "metadata": {
          },
          "source": "Mixtures"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "Letâs do one more example from _Dungeons&Dragons_. Suppose I have a box of dice with the following inventory:"
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "5   4-sided dice\n4   6-sided dice\n3   8-sided dice\n2  12-sided dice\n1  20-sided die",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "I choose a die from the box and roll it. What is the distribution of the outcome?"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "If you know which die it is, the answer is easy. A die with `n` sides yields a uniform distribution from 1 to `n` , including both."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "But if we donât know which die it is, the resulting distribution is a **mixture** of uniform distributions with different bounds. In general, this kind of mixture does not fit any simple mathematical model, but it is straightforward to compute the distribution in the form of a PMF."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "As always, one option is to simulate the scenario, generate a random sample, and compute the PMF of the sample. This approach is simple and it generates an approximate solution quickly. But if we want an exact solution, we need a different approach."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "Letâs start with a simple version of the problem where there are only two dice, one with 6 sides and one with 8. We can make a Pmf to represent each die:"
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "    d6 = Die(6)\n    d8 = Die(8)",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "Then we create a Pmf to represent the mixture:"
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "    mix = thinkbayes.Pmf()\n    for die in [d6, d8]:\n        for outcome, prob in die.Items():\n            mix.Incr(outcome, prob)\n    mix.Normalize()",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "The first loop enumerates the dice; the second enumerates the outcomes and their probabilities. Inside the loop, `Pmf.Incr` adds up the contributions from the two distributions."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "This code assumes that the two dice are equally likely. More generally, we need to know the probability of each die so we can weight the outcomes accordingly."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "First we create a Pmf that maps from each die to the probability it is selected:"
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "    pmf_dice = thinkbayes.Pmf()\n    pmf_dice.Set(Die(4), 2)\n    pmf_dice.Set(Die(6), 3)\n    pmf_dice.Set(Die(8), 2)\n    pmf_dice.Set(Die(12), 1)\n    pmf_dice.Set(Die(20), 1)\n    pmf_dice.Normalize()",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "Next we need a more general version of the mixture algorithm:"
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "    mix = thinkbayes.Pmf()\n    for die, weight in pmf_dice.Items():\n        for outcome, prob in die.Items():\n            mix.Incr(outcome, weight*prob)",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "Now each die has a weight associated with it (which makes it a weighted die, I suppose). When we add each outcome to the mixture, its probability is multiplied by `weight` ."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "FigureÂ 5-3 shows the result. As expected, values 1 through 4 are the most likely because any die can produce them. Values above 12 are unlikely because there is only one die in the box that can produce them (and it does so less than half the time)."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "<figure id=\"fig.dungeons3\" style=\"float: none\"><img src=\"files/images/thba_0503.png\"><figcaption>Distribution outcome for random die from a box.</figcaption></figure>"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "`thinkbayes` provides a function named `MakeMixture` that encapsulates this algorithm, so we could have written:"
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "    mix = thinkbayes.MakeMixture(pmf_dice)",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "Weâll use `MakeMixture` again in Chapters [ChapterÂ 7](ch07.html#prediction) and [ChapterÂ 8](ch08.html#observer)."
        },
        {
          "cell_type": "heading",
          "level": 2,
          "metadata": {
          },
          "source": "Discussion"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "Other than the odds form of Bayesâs theorem, this chapter is not specifically Bayesian. But Bayesian analysis is all about distributions, so it is important to understand the concept of a distribution well. From a computational point of view, a distribution is any data structure that represents a set of values (possible outcomes of a random process) and their probabilities."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "We have seen two representations of distributions: Pmfs and Cdfs. These representations are equivalent in the sense that they contain the same information, so you can convert from one to the other. The primary difference between them is performance: some operations are faster and easier with a Pmf; others are faster with a Cdf."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "The other goal of this chapter is to introduce operations that act on distributions, like `Pmf.__add__` , `Cdf.Max` , and `thinkbayes.MakeMixture` . We will use these operations later, but I introduce them now to encourage you to think of a distribution as a fundamental unit of computation, not just a container for values and probabilities."
        }
      ],
      "metadata": {
      }
    }
  ]
}